{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bike Sharing Assignment\n",
    "\n",
    "<b>Problem Statement</b><br/>\n",
    "A US bike-sharing provider BoomBikes has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state.\n",
    "\n",
    "In such an attempt, BoomBikes aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people's needs once the situation gets better all around and stand out from other service providers and make huge profits.\n",
    "\n",
    "They have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\n",
    "- Which variables are significant in predicting the demand for shared bikes.\n",
    "- How well those variables describe the bike demands "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: Reading and Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the necessary Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>01-01-2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.110847</td>\n",
       "      <td>18.18125</td>\n",
       "      <td>80.5833</td>\n",
       "      <td>10.749882</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>02-01-2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.902598</td>\n",
       "      <td>17.68695</td>\n",
       "      <td>69.6087</td>\n",
       "      <td>16.652113</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>03-01-2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.050924</td>\n",
       "      <td>9.47025</td>\n",
       "      <td>43.7273</td>\n",
       "      <td>16.636703</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>04-01-2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>10.60610</td>\n",
       "      <td>59.0435</td>\n",
       "      <td>10.739832</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>05-01-2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.305237</td>\n",
       "      <td>11.46350</td>\n",
       "      <td>43.6957</td>\n",
       "      <td>12.522300</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  01-01-2018       1   0     1        0        6           0   \n",
       "1        2  02-01-2018       1   0     1        0        0           0   \n",
       "2        3  03-01-2018       1   0     1        0        1           1   \n",
       "3        4  04-01-2018       1   0     1        0        2           1   \n",
       "4        5  05-01-2018       1   0     1        0        3           1   \n",
       "\n",
       "   weathersit       temp     atemp      hum  windspeed  casual  registered  \\\n",
       "0           2  14.110847  18.18125  80.5833  10.749882     331         654   \n",
       "1           2  14.902598  17.68695  69.6087  16.652113     131         670   \n",
       "2           1   8.050924   9.47025  43.7273  16.636703     120        1229   \n",
       "3           1   8.200000  10.60610  59.0435  10.739832     108        1454   \n",
       "4           1   9.305237  11.46350  43.6957  12.522300      82        1518   \n",
       "\n",
       "    cnt  \n",
       "0   985  \n",
       "1   801  \n",
       "2  1349  \n",
       "3  1562  \n",
       "4  1600  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "bikes_df = pd.read_csv('day.csv')\n",
    "bikes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of the dataframe\n",
    "bikes_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No. of rows = 730\n",
    "#### No. of columns = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 730 entries, 0 to 729\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   instant     730 non-null    int64  \n",
      " 1   dteday      730 non-null    object \n",
      " 2   season      730 non-null    int64  \n",
      " 3   yr          730 non-null    int64  \n",
      " 4   mnth        730 non-null    int64  \n",
      " 5   holiday     730 non-null    int64  \n",
      " 6   weekday     730 non-null    int64  \n",
      " 7   workingday  730 non-null    int64  \n",
      " 8   weathersit  730 non-null    int64  \n",
      " 9   temp        730 non-null    float64\n",
      " 10  atemp       730 non-null    float64\n",
      " 11  hum         730 non-null    float64\n",
      " 12  windspeed   730 non-null    float64\n",
      " 13  casual      730 non-null    int64  \n",
      " 14  registered  730 non-null    int64  \n",
      " 15  cnt         730 non-null    int64  \n",
      "dtypes: float64(4), int64(11), object(1)\n",
      "memory usage: 91.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking the datatypes of dataframe\n",
    "\n",
    "bikes_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No missing values observed in all the columns of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns like instant, dteday, casual, registered\n",
    "# instant is an index\n",
    "# Ignoring dteday as we already have year & month as separate columns\n",
    "# Ignoring casual & registered as cnt already has total count considering both casual & registered users\n",
    "\n",
    "bikes_df.drop(['instant', 'dteday', 'casual', 'registered'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns holiday as 'working_day' as information about holiday & weekend\n",
    "\n",
    "bikes_df.drop(['holiday'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 730 entries, 0 to 729\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   season      730 non-null    int64  \n",
      " 1   yr          730 non-null    int64  \n",
      " 2   mnth        730 non-null    int64  \n",
      " 3   weekday     730 non-null    int64  \n",
      " 4   workingday  730 non-null    int64  \n",
      " 5   weathersit  730 non-null    int64  \n",
      " 6   temp        730 non-null    float64\n",
      " 7   atemp       730 non-null    float64\n",
      " 8   hum         730 non-null    float64\n",
      " 9   windspeed   730 non-null    float64\n",
      " 10  cnt         730 non-null    int64  \n",
      "dtypes: float64(4), int64(7)\n",
      "memory usage: 62.9 KB\n"
     ]
    }
   ],
   "source": [
    "bikes_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns for better readability\n",
    "\n",
    "bikes_df.rename(columns={'yr': 'year', 'mnth': 'month', 'hum': 'humidity', 'cnt': 'count', 'weathersit': 'weather'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 730 entries, 0 to 729\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   season      730 non-null    int64  \n",
      " 1   year        730 non-null    int64  \n",
      " 2   month       730 non-null    int64  \n",
      " 3   weekday     730 non-null    int64  \n",
      " 4   workingday  730 non-null    int64  \n",
      " 5   weather     730 non-null    int64  \n",
      " 6   temp        730 non-null    float64\n",
      " 7   atemp       730 non-null    float64\n",
      " 8   humidity    730 non-null    float64\n",
      " 9   windspeed   730 non-null    float64\n",
      " 10  count       730 non-null    int64  \n",
      "dtypes: float64(4), int64(7)\n",
      "memory usage: 62.9 KB\n"
     ]
    }
   ],
   "source": [
    "bikes_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the actual values for categorical variables for visualization and splitting to dummy variables\n",
    "\n",
    "bikes_df.season = bikes_df.season.map({1:'spring', 2:'summer', 3:'fall', 4:'winter'})\n",
    "bikes_df.month = bikes_df.month.map({1:'jan', 2:'feb', 3:'mar', 4:'apr', 5:'may', 6:'jun', 7:'jul', 8:'aug',9:'sep', 10:'oct', 11:'nov', 12:'dec',})\n",
    "bikes_df.weekday = bikes_df.weekday.map({0:'sunday', 1:'monday', 2:'tuesday', 3:'wednesday', 4:'thursday', 5:'friday', 6:'saturday'})\n",
    "bikes_df.weather = bikes_df.weather.map({1:'clear', 2:'mist', 3:'light_snow', 4:'heavy_rain'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for unique values in each columns\n",
    "\n",
    "bikes_df.nunique(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising numerical variables using pairplot\n",
    "\n",
    "num_cols = ['temp', 'atemp', 'humidity', 'windspeed', 'count']\n",
    "\n",
    "sns.pairplot(bikes_df[num_cols])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Count seems to have more correlation with temp and atemp variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the correlation using heatmap\n",
    "\n",
    "sns.heatmap(bikes_df[num_cols].corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can observe that temp and atemp variables have high correlation. So, dropping atemp column\n",
    "\n",
    "bikes_df.drop('atemp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing categorical variables. Plotting box plots for those.\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.subplot(2,3,1)\n",
    "sns.boxplot(x = 'season', y = 'count', data = bikes_df)\n",
    "plt.subplot(2,3,2)\n",
    "sns.boxplot(x = 'year', y = 'count', data = bikes_df)\n",
    "plt.subplot(2,3,3)\n",
    "sns.boxplot(x = 'month', y = 'count', data = bikes_df)\n",
    "plt.subplot(2,3,4)\n",
    "sns.boxplot(x = 'weekday', y = 'count', data = bikes_df)\n",
    "plt.subplot(2,3,5)\n",
    "sns.boxplot(x = 'workingday', y = 'count', data = bikes_df)\n",
    "plt.subplot(2,3,6)\n",
    "sns.boxplot(x = 'weather', y = 'count', data = bikes_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "\n",
    "- In fall season, the rentals are higher\n",
    "- The rentals have increased from 2018 to 2019\n",
    "- Months: Jul to Sep, the rentals are higher\n",
    "- When weather is clear, the rentals are higher\n",
    "- Don't see any significant trend from weekday and workingday bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables for category variables for season, month, weekday, weathersituation\n",
    "\n",
    "seasons = pd.get_dummies(bikes_df.season, drop_first=True)\n",
    "months = pd.get_dummies(bikes_df.month, drop_first=True)\n",
    "days = pd.get_dummies(bikes_df.weekday, drop_first=True)\n",
    "weather = pd.get_dummies(bikes_df.weather, drop_first=True)\n",
    "\n",
    "# Adding results to the original dataframe\n",
    "\n",
    "bikes_df = pd.concat([bikes_df, seasons], axis=1)\n",
    "bikes_df = pd.concat([bikes_df, months], axis=1)\n",
    "bikes_df = pd.concat([bikes_df, days], axis=1)\n",
    "bikes_df = pd.concat([bikes_df, weather], axis=1)\n",
    "\n",
    "\n",
    "# Dropping original columns as we have dummy columns\n",
    "bikes_df.drop(['season', 'month', 'weekday', 'weather'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "bikes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Splitting data into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test sets in the ratio 70:30\n",
    "\n",
    "# We specify this so that the train and test data set always have the same rows, respectively\n",
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(bikes_df, train_size=0.7, test_size=0.3, random_state=100)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rescaling feature using Min-Max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaler() to all columns except the 'yes-no' and 'dummy' variables\n",
    "\n",
    "num_cols = ['temp', 'humidity', 'windspeed', 'count']\n",
    "df_train[num_cols] = scaler.fit_transform(df_train[num_cols])\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing into X and Y sets for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.pop('count')\n",
    "X_train = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: LinearRegression with Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running RFE with the output number of the variables equal to 10\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# Run RFE\n",
    "rfe = RFE(lm, 10)\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns[rfe.support_]\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights from RFE:\n",
    "- Temp, Windspeed, Humidity, Seasons(Spring), Year, Months(Jul, Sep), WeatherSit(Light_snow, Mist), Weekday(Saturday) are considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns which are omitted by RFE\n",
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building model using statsmodel, for detailed statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe = X_train[cols]\n",
    "\n",
    "# Adding a constant variable for statsmodel\n",
    "X_train_rfe = sm.add_constant(X_train_rfe)\n",
    "\n",
    "# Running the linear regression model (OLS)\n",
    "lr_sm = sm.OLS(y_train, X_train_rfe).fit()\n",
    "\n",
    "lr_sm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights:\n",
    "- R-squared = 0.829\n",
    "- Adj. R-squared = 0.825\n",
    "- p-value of saturday is on a higher side 0.066. So, let check VIF too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the constant variable from the dataframe \n",
    "\n",
    "X_train_rfe = X_train_rfe.drop('const', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the VIF values of the feature variables. \n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train_rfe.columns # Ignoring the const \n",
    "vif['VIF'] = [variance_inflation_factor(X_train_rfe.values, i) for i in range(X_train_rfe.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping variable 'saturday' because of higher p-value of 0.066\n",
    "\n",
    "X_train_sm = X_train_rfe.drop('saturday',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulding another linear model with the new dataset\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train_sm)\n",
    "\n",
    "lr2_sm = sm.OLS(y_train, X_train_sm).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr2_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "\n",
    "- Adj.R-squared value is same as previous model 0.825 after dropping 'saturday' variable\n",
    "- p-value are low indicating all variables are significant\n",
    "- Noticed some of the coefficients have negative sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing VIF\n",
    "\n",
    "X_train_sm = X_train_sm.drop('const', axis=1)\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train_sm.columns # Ignoring the const \n",
    "vif['VIF'] = [variance_inflation_factor(X_train_sm.values, i) for i in range(X_train_sm.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- We generally want a VIF that is less than 5. So there are clearly some variables we need to drop. \n",
    "- So, we will drop 'humidity' and re-run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping variable 'humidity' because of high VIF of 14.88\n",
    "X_train_sm = X_train_sm.drop('humidity',axis=1)\n",
    "\n",
    "# bulding another linear model with the newer dataset\n",
    "X_train_sm = sm.add_constant(X_train_sm)\n",
    "lr3_sm = sm.OLS(y_train, X_train_sm).fit()\n",
    "\n",
    "# summary statistics of newer model\n",
    "print(lr3_sm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing VIF\n",
    "\n",
    "X_train_sm = X_train_sm.drop('const', axis=1)\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train_sm.columns # Ignoring the const \n",
    "vif['VIF'] = [variance_inflation_factor(X_train_sm.values, i) for i in range(X_train_sm.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights:\n",
    "- For the lr3_sm model, all the p-values are low which indicates all variables are significant\n",
    "- Also, VIF values are less than 5.\n",
    "- Adj Rsquare value is 0.821\n",
    "\n",
    "</br>\n",
    "VIFs and p-values both are within an acceptable range. So, using lr3_sm model to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Residual Analysis of the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X_train_sm)\n",
    "\n",
    "# predicting using the latest model lr3_sm model\n",
    "y_train_count = lr3_sm.predict(X_train_sm)\n",
    "\n",
    "# residuals\n",
    "res = y_train - y_train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the error terms\n",
    "fig = plt.figure()\n",
    "sns.distplot(res, bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 20)# Plot heading \n",
    "plt.xlabel('Errors', fontsize = 18)       # X-Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights:\n",
    "- The error terms of the latest model (lr3_sm) gives a normal distribution with mean around 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for patterns in the residuals\n",
    "\n",
    "plt.scatter(np.arange(0,len(X_train_sm),1), res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are confident that the model fit isn't by chance, and has decent predictive power. \n",
    "- Although, the variance of residuals increasing with X indicates that there is significant variation that this model is unable to explain.\n",
    "- As you can see, the regression line is a pretty good fit to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Making predictions using final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying scaling on the test set\n",
    "\n",
    "num_cols = ['temp', 'humidity', 'windspeed', 'count']\n",
    "df_test[num_cols] = scaler.fit_transform(df_test[num_cols])\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing into X_test and y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test.pop('count')\n",
    "X_test = df_test[cols]\n",
    "\n",
    "print(y_test.head())\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding constant variable to test dataframe\n",
    "X_test_sm = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping variables which were dropped during model training from X_test \n",
    "\n",
    "X_test_sm = X_test_sm.drop(['humidity', 'saturday'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sm = lr3_sm.predict(X_test_sm)\n",
    "y_pred_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Model Evalation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(y_test, y_pred_sm)\n",
    "fig.suptitle('y_test vs y_pred', fontsize = 20)              # Plot heading \n",
    "plt.xlabel('y_test', fontsize = 18)                          # X-label\n",
    "plt.ylabel('y_pred', fontsize = 16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "- The y_test vs y_pred spread shows the linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr3_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The equation of the best fit line is:\n",
    "\n",
    "$ count = 0.304 + 0.236 * year + 0.394 * temp - 0.153 * windspeed - 0.146 * spring - 0.073 * jul + 0.053 * sep - 0.275 * lightsnow - 0.080 * mist $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rsquared score on test set\n",
    "print(r2_score(y_test, y_pred_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rsquared on train & test sets with the final model\n",
    "\n",
    "- Rsquared score on train set: 0.824\n",
    "- Rsquared score on test set: 0.789\n",
    "\n",
    "</br>\n",
    "Model does a decent job on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adj. Rsquared\n",
    "\n",
    "$ Adj. R2 = 1−(1−R2)∗(n−1)/(n−p−1) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_test_sm.shape[0]\n",
    "p = X_test_sm.shape[1]\n",
    "\n",
    "adj_r2 = 1 - (1-r2_score(y_test, y_pred_sm))* (n-1)/(n-p-1)\n",
    "adj_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "The following are the variables which are significant in predicting the demand for shared bikes.\n",
    "  - Year\n",
    "  - Temp\n",
    "  - Windspeed\n",
    "  - Spring season\n",
    "  - Jul & Sep months\n",
    "  - Light snow/rain & Mist weather\n",
    "\n",
    "How well those variables describe the bike demands\n",
    "-  $ count = 0.304 + 0.236 * year + 0.394 * temp - 0.153 * windspeed - 0.146 * spring - 0.073 * jul + 0.053 * sep - 0.275 * lightsnow - 0.080 * mist $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
